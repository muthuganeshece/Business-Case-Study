Jamboree has helped thousands of students like you make it to top colleges abroad. Be it GMAT, GRE or SAT, their unique problem-solving methods ensure maximum scores with minimum effort.
They recently launched a feature where students/learners can come to their website and check their probability of getting into the IVY league college. 
This feature estimates the chances of graduate admission from an Indian perspective.


How can you help here?

Your analysis will help Jamboree in understanding what factors are important in graduate admissions and how these factors are interrelated among themselves. 
It will also help predict one's chances of admission given the rest of the variables.


Dataset: jamboree_admission.csv

Dataset Link: 


Column Profiling:

Serial No. (Unique row ID)
GRE Scores (out of 340)
TOEFL Scores (out of 120)
University Rating (out of 5)
Statement of Purpose and Letter of Recommendation Strength (out of 5)
Undergraduate GPA (out of 10)
Research Experience (either 0 or 1)
Chance of Admit (ranging from 0 to 1)

Concept Used:

Exploratory Data Analysis
Linear Regression

What does good looks like?

Import the dataset and do usual exploratory data analysis steps like checking the structure & characteristics of the dataset.
Drop the unique row Identifier if you see any. This step is important as you don’t want your model to build some understanding based on row numbers.
Use Non-graphical and graphical analysis for getting inferences about variables.
This can be done by checking the distribution of variables of graduate applicants.
Once you’ve ensured that students with varied merit apply for the university, you can start understanding the relationship between different factors responsible for graduate admissions.
Check correlation among independent variables and how they interact with each other.
Use Linear Regression from (Statsmodel library) and explain the results.
Test the assumptions of linear regression:
Multicollinearity check by VIF score
Mean of residuals
Linearity of variables (no pattern in residual plot)
Test for Homoscedasticity
Normality of residuals
Do model evaluation- MAE, RMSE, R2 score, Adjusted R2.
Provide actionable Insights & Recommendations
Try out different Linear Regressions
Evaluation Criteria (100 Points):

Define Problem Statement and perform Exploratory Data Analysis (10 points)
Definition of problem (as per given problem statement with additional views)
Observations on shape of data, data types of all the attributes, conversion of categorical attributes to 'category' (If required) , missing value detection, statistical summary.
Univariate Analysis (distribution plots of all the continuous variable(s) barplots/countplots of all the categorical variables)
Bivariate Analysis (Relationships between important variables such as workday and count, season and count, weather and count.
Illustrate the insights based on EDA
Comments on range of attributes, outliers of various attributes
Comments on the distribution of the variables and relationship between them
Comments for each univariate and bivariate plots
Data Preprocessing (10 Points)
	Duplicate value check
	Missing value treatment
	Outlier treatment
	Feature engineering
	Data preparation for modeling
Model building (10 Points)
	Build the Linear Regression model and comment on the model statistics
	Display model coefficients with column names
	Try out Ridge and Lasso regression
Testing the assumptions of the linear regression model (50 Points)
	Multicollinearity check by VIF score (variables are dropped one-by-one till none has VIF>5) (10 Points)
	The mean of residuals is nearly zero (10 Points)
	Linearity of variables (no pattern in the residual plot) (10 Points)
	Test for Homoscedasticity (10 Points)
	Normality of residuals (almost bell-shaped curve in residuals distribution, points in QQ plot are almost all on the line) (10 Points)
	Model performance evaluation (10 Points)
		Metrics checked - MAE, RMSE, R2, Adj R2
		Train and test performances are checked
		Comments on the performance measures and if there is any need to improve the model or not
Actionable Insights & Recommendations (10 Points)
Comments on significance of predictor variables
Comments on additional data sources for model improvement, model implementation in real world, potential business benefits from improving the model (These are key to differentiating a good and an excellent solution)

GRE Score: Normally distributed and no iqr outliers are observed

- Data Characteristics
	- **Serial No.**: 
		- All are Unique values might not be helpful for prediction, hence should be ignored before prediction
	- **GRE Score, TOEFL Score**: 
		- Mean ~= Median indicating Central Tendency
		- Data is distributed normally and having spread out peak or flat peak
		- No gaps in distribution plot indicates the data is Continuous with no missing range 
	- **Cumulative Grade Point Average (CGPA)**: 
		- Ranges from 6.8 to 9.92, 
		- Data is distributed normally and having sharp peak
		- Gap between 7 and 7.5 in the distribution plot indicates the missing range in the data
	- **University Rating**: 
		- Ordinal Feature ranges from 1 to 5
		- Ratings in the range 2-4 being 80% of proportion
		- Average rated universities (3) are the most in dataset
	- ** Statement of Purpose (SOP)**: 
		- Ordinal Feature ranges from 1 to 5 with resolution 0.5
		- Strength in the range 2.5-4.5 being 80% of proportion
		- Lowest strength (1) is neglegible (1.2%) and can be ignored or merged
	- **Letter of Recommendation (LOR)**: 
		- Ordinal Feature ranges from 1 to 5 with resolution 0.5
		- Strength in the range 3-4 being ~60% of proportion
		- Lowest strength (1) is neglegible (0.2%)
	- **Research**: 
		- Binary categorical feature with equal distribution		
	- **Change of Admit**: 
		- Probability of getting Admission ranges from 0.4 to 1
- Exploratory Data Analysis		
	- No null values and no iqr outliers are identified indicating clean dataset
	- Students from universities with higher ratings (3+) are more likely to have research experience
	- Students having research experience are more likely to have higher SOP and LOR strengths (3+)
	- Students having research experience are mostly likely to get higher scores in GRE, TOEFL and Curriculum
	- Strength of relationship between categorical features: (University rating and SOP) > (University rating and LOR) > (SOP and LOR)
	- All 3 numerical features are highly linearly correlated
	- Students having high CGPA are more likely to have higher GRE and TOEFL Score
	- Students scored more in the GRE, TOEFL and Curriculum are having higher SOP strength, LOR strength
	- Balanced distribution of the target is observed for <0.5 (~50%) and > 0.5 (~50%)
	- GRE Score, TOEFL Score and CGPA all are linearly correlated with Chance of getting Admission
	- University rating, SOP, LOR and Research experience are positively and linearly correlated with Chance of Admission
	- PCA Analysis:
		- The first principal component from PCA explains approximately 65% of the variance in the data
		- The first principal component is constructed with nearly equal contributions from all features in the dataset
		- Out of 7 features from the dataset, First 3 principal components captures >85% of variance in data
	- Statistical Tests:
		- Chance of admission for each Category of University Rating, LOR and SOP are significantly different indicating the segregration is independent
		- The contingency test confirms that the categorical features (University Rating, LOR and SOP) are significantly dependent on each other
	- Linear Regression:
		- Train: RMSE = 0.042, R2 Score = 0.83, Adj. R2 Score = 0.83
		  Test:  RMSE = 0.044, R2 Score = 0.77, Adj. R2 Score = 0.76
		- Moderate performance of the model
		- Based on the coefficients, GRE SCore, TOEFL Score, CGPA, LOR are given higher weightage indicating the significance of the features for the prediction
		- Weightages of all the features are positive indicating the positive correlation		
	- Polynomial Regression: (Degree = 2)
		- Train: RMSE = 0.039, R2 Score = 0.84, Adj. R2 Score = 0.83
		  Test:  RMSE = 0.047, R2 Score = 0.76, Adj. R2 Score = 0.634
		- Doesn't improve the performance much
		- Slightly overfits based on the Train and Test RMSE
	- Ridge Regression:
		- Train: RMSE = 0.042, R2 Score = 0.83, Adj. R2 Score = 0.83
		  Test:  RMSE = 0.044, R2 Score = 0.77, Adj. R2 Score = 0.76	
		- The test performance of the  model improves significantly compared to Linear Regression model(7% improvement)
		- Increasing the regularization constant  increases RMSE and decreases R2 score which is undesirable
	- Lasso Regression:
		- Train: RMSE = 0.042, R2 Score = 0.83, Adj. R2 Score = 0.82
		  Test:  RMSE = 0.043, R2 Score = 0.82, Adj. R2 Score = 0.80	
		- The test performance of the  model improves significantly compared to Linear Regression model(7% improvement) but same as that of Ridge
		- Increasing the regularization constant drastically increases RMSE and decreases R2 score which is undesirable		
		- Significant improvement observed at very low regularization constant values (<0.01)
	- Elastic Net Regression:
		- Similar performance as that of Ridge and Lasso Regression, no significant improvement observed
	- Multicollinearity Analysis: 
		- GRE, TOEFL Score and CGPA having very high VIF value indicating the high linear dependency between the features
		- Without GRE and TOEFL Score, VIF is drastically reduced for CGPA indicating the dependency of the 3 features
		- Without University rating and SOP, VIF of LOR is drastically reducted indicating the dependency of the 3 features
	- Removing collinear features doesn't improve the performance of linear regression model but slightly reduces its performance
	- All the features have high correlation with Target variable and the clear curvature in the residuals plot indicates non-linearity
	- Residual is almost normally distributed with slight skew
Recommendations:
- Data Preprocessing:
	- As the population of certain categories are less in the following categorical features, categories can be merged
		- SOP: Ratings 1, 1.5 and 2.0 can be merged, 4.5 and 5.0 can be merged
		- LOR: Ratings 1, 1.5, 2.0 and 2.5 can be merged, 4.5 and 5.0 can be merged
		- University Rating: Ratings 1 and 2 can be merged, 4 and 5 can be merged
	- Transform all the ratings to ordinal categorical data
- Modeling:
	- Simple Linear Regression model provides mediocre performance hence non linear model can be applied
	- Polynomial Regressiuon of degree 2 also doesn't improve the performance, higher degree can be tried. However, model overfitting behaviour should be monitored
	- In the family of linear models, Ridge Regression provides better performance (7% improvement compared to Linear Regression) at alpha <= 0.1
	- A clear curvature in the residuals plot indicates non-linearity of the data, hence non linear model is required to improve the performance of the model
	

